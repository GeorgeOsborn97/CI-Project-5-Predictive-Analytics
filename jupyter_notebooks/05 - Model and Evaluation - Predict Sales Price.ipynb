{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Evaluation - Predict Sales Price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit and evaluate a regression model to predict Sales Price\n",
    "* Utilise Hyperparameter Optimisation and Grid Search CV to design a well suited and functioning model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outputs/datasets/cleaned/clean_house_price_records.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In case you have any additional comments that don't fit in the previous bullets, please state them here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working Directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/CI-Project-5-Predictive-Analytics/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to make the parent of the current directory the new current directory\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/CI-Project-5-Predictive-Analytics'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cleaned Data and Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine import transformation as vt\n",
    "\n",
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required cleaned data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the .csv file into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2003</td>\n",
       "      <td>1710</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8450</td>\n",
       "      <td>65</td>\n",
       "      <td>196</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>TA</td>\n",
       "      <td>9600</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>3</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2001</td>\n",
       "      <td>1786</td>\n",
       "      <td>Gd</td>\n",
       "      <td>11250</td>\n",
       "      <td>68</td>\n",
       "      <td>162</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>216</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>540</td>\n",
       "      <td>642</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1998</td>\n",
       "      <td>1717</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9550</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>756</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Av</td>\n",
       "      <td>655</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>490</td>\n",
       "      <td>836</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2000</td>\n",
       "      <td>2198</td>\n",
       "      <td>Gd</td>\n",
       "      <td>14260</td>\n",
       "      <td>84</td>\n",
       "      <td>350</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1145</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856       854             3           No         706          GLQ   \n",
       "1      1262         0             3           Gd         978          ALQ   \n",
       "2       920       866             3           Mn         486          GLQ   \n",
       "3       961         0             0           No         216          ALQ   \n",
       "4      1145         0             4           Av         655          GLQ   \n",
       "\n",
       "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  GrLivArea KitchenQual  \\\n",
       "0        150         548          RFn         2003       1710          Gd   \n",
       "1        284         460          RFn         1976       1262          TA   \n",
       "2        434         608          RFn         2001       1786          Gd   \n",
       "3        540         642          Unf         1998       1717          Gd   \n",
       "4        490         836          RFn         2000       2198          Gd   \n",
       "\n",
       "   LotArea  LotFrontage  MasVnrArea  OpenPorchSF  OverallCond  OverallQual  \\\n",
       "0     8450           65         196           61            5            7   \n",
       "1     9600           80           0            0            8            6   \n",
       "2    11250           68         162           42            5            7   \n",
       "3     9550           60           0           35            5            7   \n",
       "4    14260           84         350           84            5            8   \n",
       "\n",
       "   TotalBsmtSF  YearBuilt  YearRemodAdd  SalePrice  \n",
       "0          856       2003          2003     208500  \n",
       "1         1262       1976          1976     181500  \n",
       "2          920       2001          2002     223500  \n",
       "3          756       1915          1970     140000  \n",
       "4         1145       2000          2000     250000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"outputs/datasets/cleaned/clean_house_price_records.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the ML Regressor Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The pipeline below implements the feature engineering steps that we concluded on in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimisation(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                   variables=['BsmtExposure',\n",
    "                                                              'BsmtFinType1',\n",
    "                                                              'GarageFinish',\n",
    "                                                              'KitchenQual'])),\n",
    "        \n",
    "        (\"NumericLogTransform\",vt.LogTransformer(variables=['1stFlrSF', 'GrLivArea', 'LotArea',])),\n",
    "        \n",
    "        (\"NumericYeoJohnsonTransform\",vt.YeoJohnsonTransformer(variables=['BsmtUnfSF'])),\n",
    "        \n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "                                                            method=\"spearman\",\n",
    "                                                            threshold=0.6,\n",
    "                                                            selection_method=\"cardinality\")),\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below is the Hyperparameter Optimisation function as defined in the Code Institute lesson material relating to Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineOptimisation(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 21) (1168,) (292, 21) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV - Sklearn.\n",
    "\n",
    "* We shall use the default hyperparameters to search through the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for DecisionTreeRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for AdaBoostRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can now check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.676578</td>\n",
       "      <td>0.798403</td>\n",
       "      <td>0.862491</td>\n",
       "      <td>0.071609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.701255</td>\n",
       "      <td>0.79697</td>\n",
       "      <td>0.844212</td>\n",
       "      <td>0.055843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.608028</td>\n",
       "      <td>0.778348</td>\n",
       "      <td>0.841748</td>\n",
       "      <td>0.088047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.658521</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>0.822257</td>\n",
       "      <td>0.056768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.727124</td>\n",
       "      <td>0.775717</td>\n",
       "      <td>0.066604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.564369</td>\n",
       "      <td>0.700756</td>\n",
       "      <td>0.751493</td>\n",
       "      <td>0.070433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.312063</td>\n",
       "      <td>0.551501</td>\n",
       "      <td>0.648486</td>\n",
       "      <td>0.122515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score max_score std_score\n",
       "3        ExtraTreesRegressor  0.676578   0.798403  0.862491  0.071609\n",
       "2      RandomForestRegressor  0.701255    0.79697  0.844212  0.055843\n",
       "5  GradientBoostingRegressor  0.608028   0.778348  0.841748  0.088047\n",
       "0           LinearRegression  0.658521   0.737333  0.822257  0.056768\n",
       "6               XGBRegressor  0.595537   0.727124  0.775717  0.066604\n",
       "4          AdaBoostRegressor  0.564369   0.700756  0.751493  0.070433\n",
       "1      DecisionTreeRegressor  0.312063   0.551501  0.648486  0.122515"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we return to our business case specifically point 9 \"What are the criteria for the performance goal of the predictions?\". We can see that the minimum requirement of an r2 score is 0.75.\n",
    "* If we look at the top 3 algorithms we see that all 3 pass this criteria when we review the mean_score. \n",
    "* ExtraTreesRegressor appears to be the best.\n",
    "* We shall do an extensive search on this algorithm to determine the best hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"ExtraTreesRegressor\":RandomForestRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\":{\n",
    "        'model__n_estimators': [50,100,150,200,250,300,500,1000],\n",
    "        'model__max_depth': [2,8,16,32,None],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.706932</td>\n",
       "      <td>0.803771</td>\n",
       "      <td>0.84859</td>\n",
       "      <td>0.054214</td>\n",
       "      <td>16</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.705478</td>\n",
       "      <td>0.802556</td>\n",
       "      <td>0.848687</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703491</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.847821</td>\n",
       "      <td>0.055487</td>\n",
       "      <td>16</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.702522</td>\n",
       "      <td>0.800943</td>\n",
       "      <td>0.848183</td>\n",
       "      <td>0.055892</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703403</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.845799</td>\n",
       "      <td>0.054369</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703855</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>0.848546</td>\n",
       "      <td>0.056089</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703855</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>0.848546</td>\n",
       "      <td>0.056089</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.70269</td>\n",
       "      <td>0.799384</td>\n",
       "      <td>0.848151</td>\n",
       "      <td>0.056461</td>\n",
       "      <td>None</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.70269</td>\n",
       "      <td>0.799384</td>\n",
       "      <td>0.848151</td>\n",
       "      <td>0.056461</td>\n",
       "      <td>32</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703555</td>\n",
       "      <td>0.799378</td>\n",
       "      <td>0.848423</td>\n",
       "      <td>0.056369</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703555</td>\n",
       "      <td>0.799378</td>\n",
       "      <td>0.848423</td>\n",
       "      <td>0.056369</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.701128</td>\n",
       "      <td>0.799337</td>\n",
       "      <td>0.847043</td>\n",
       "      <td>0.056222</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>0.799033</td>\n",
       "      <td>0.848788</td>\n",
       "      <td>0.057339</td>\n",
       "      <td>32</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>0.799033</td>\n",
       "      <td>0.848788</td>\n",
       "      <td>0.057339</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.697081</td>\n",
       "      <td>0.798975</td>\n",
       "      <td>0.849963</td>\n",
       "      <td>0.058173</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.697521</td>\n",
       "      <td>0.798939</td>\n",
       "      <td>0.84697</td>\n",
       "      <td>0.057308</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.701874</td>\n",
       "      <td>0.79849</td>\n",
       "      <td>0.846384</td>\n",
       "      <td>0.056223</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.699847</td>\n",
       "      <td>0.798487</td>\n",
       "      <td>0.846423</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.702203</td>\n",
       "      <td>0.797943</td>\n",
       "      <td>0.845064</td>\n",
       "      <td>0.055927</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.696207</td>\n",
       "      <td>0.79786</td>\n",
       "      <td>0.849392</td>\n",
       "      <td>0.058624</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.696207</td>\n",
       "      <td>0.79786</td>\n",
       "      <td>0.849392</td>\n",
       "      <td>0.058624</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.699742</td>\n",
       "      <td>0.797621</td>\n",
       "      <td>0.842712</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.696281</td>\n",
       "      <td>0.797365</td>\n",
       "      <td>0.847675</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.696281</td>\n",
       "      <td>0.797365</td>\n",
       "      <td>0.847675</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.693931</td>\n",
       "      <td>0.797251</td>\n",
       "      <td>0.847477</td>\n",
       "      <td>0.059078</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.695931</td>\n",
       "      <td>0.797142</td>\n",
       "      <td>0.848687</td>\n",
       "      <td>0.058693</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.701255</td>\n",
       "      <td>0.79697</td>\n",
       "      <td>0.844212</td>\n",
       "      <td>0.055843</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.701255</td>\n",
       "      <td>0.79697</td>\n",
       "      <td>0.844212</td>\n",
       "      <td>0.055843</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.696489</td>\n",
       "      <td>0.796108</td>\n",
       "      <td>0.848543</td>\n",
       "      <td>0.058465</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.692716</td>\n",
       "      <td>0.795749</td>\n",
       "      <td>0.846499</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703421</td>\n",
       "      <td>0.792465</td>\n",
       "      <td>0.841143</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.703421</td>\n",
       "      <td>0.792465</td>\n",
       "      <td>0.841143</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.567399</td>\n",
       "      <td>0.643697</td>\n",
       "      <td>0.713238</td>\n",
       "      <td>0.062038</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.565605</td>\n",
       "      <td>0.64223</td>\n",
       "      <td>0.713344</td>\n",
       "      <td>0.062847</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.562981</td>\n",
       "      <td>0.640741</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>0.064237</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.562159</td>\n",
       "      <td>0.640291</td>\n",
       "      <td>0.713069</td>\n",
       "      <td>0.06441</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.559267</td>\n",
       "      <td>0.639717</td>\n",
       "      <td>0.714048</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.540789</td>\n",
       "      <td>0.63834</td>\n",
       "      <td>0.705965</td>\n",
       "      <td>0.063785</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.552307</td>\n",
       "      <td>0.636964</td>\n",
       "      <td>0.71336</td>\n",
       "      <td>0.069199</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.550408</td>\n",
       "      <td>0.635966</td>\n",
       "      <td>0.71026</td>\n",
       "      <td>0.06881</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              estimator min_score mean_score max_score std_score  \\\n",
       "19  ExtraTreesRegressor  0.706932   0.803771   0.84859  0.054214   \n",
       "18  ExtraTreesRegressor  0.705478   0.802556  0.848687  0.054865   \n",
       "20  ExtraTreesRegressor  0.703491     0.8018  0.847821  0.055487   \n",
       "21  ExtraTreesRegressor  0.702522   0.800943  0.848183  0.055892   \n",
       "17  ExtraTreesRegressor  0.703403   0.800733  0.845799  0.054369   \n",
       "27  ExtraTreesRegressor  0.703855     0.8004  0.848546  0.056089   \n",
       "35  ExtraTreesRegressor  0.703855     0.8004  0.848546  0.056089   \n",
       "36  ExtraTreesRegressor   0.70269   0.799384  0.848151  0.056461   \n",
       "28  ExtraTreesRegressor   0.70269   0.799384  0.848151  0.056461   \n",
       "26  ExtraTreesRegressor  0.703555   0.799378  0.848423  0.056369   \n",
       "34  ExtraTreesRegressor  0.703555   0.799378  0.848423  0.056369   \n",
       "11  ExtraTreesRegressor  0.701128   0.799337  0.847043  0.056222   \n",
       "29  ExtraTreesRegressor  0.699605   0.799033  0.848788  0.057339   \n",
       "37  ExtraTreesRegressor  0.699605   0.799033  0.848788  0.057339   \n",
       "22  ExtraTreesRegressor  0.697081   0.798975  0.849963  0.058173   \n",
       "13  ExtraTreesRegressor  0.697521   0.798939   0.84697  0.057308   \n",
       "10  ExtraTreesRegressor  0.701874    0.79849  0.846384  0.056223   \n",
       "12  ExtraTreesRegressor  0.699847   0.798487  0.846423   0.05677   \n",
       "9   ExtraTreesRegressor  0.702203   0.797943  0.845064  0.055927   \n",
       "30  ExtraTreesRegressor  0.696207    0.79786  0.849392  0.058624   \n",
       "38  ExtraTreesRegressor  0.696207    0.79786  0.849392  0.058624   \n",
       "16  ExtraTreesRegressor  0.699742   0.797621  0.842712   0.05492   \n",
       "31  ExtraTreesRegressor  0.696281   0.797365  0.847675  0.058091   \n",
       "39  ExtraTreesRegressor  0.696281   0.797365  0.847675  0.058091   \n",
       "14  ExtraTreesRegressor  0.693931   0.797251  0.847477  0.059078   \n",
       "23  ExtraTreesRegressor  0.695931   0.797142  0.848687  0.058693   \n",
       "25  ExtraTreesRegressor  0.701255    0.79697  0.844212  0.055843   \n",
       "33  ExtraTreesRegressor  0.701255    0.79697  0.844212  0.055843   \n",
       "8   ExtraTreesRegressor  0.696489   0.796108  0.848543  0.058465   \n",
       "15  ExtraTreesRegressor  0.692716   0.795749  0.846499  0.059598   \n",
       "24  ExtraTreesRegressor  0.703421   0.792465  0.841143  0.055681   \n",
       "32  ExtraTreesRegressor  0.703421   0.792465  0.841143  0.055681   \n",
       "1   ExtraTreesRegressor  0.567399   0.643697  0.713238  0.062038   \n",
       "3   ExtraTreesRegressor  0.565605    0.64223  0.713344  0.062847   \n",
       "2   ExtraTreesRegressor  0.562981   0.640741   0.71216  0.064237   \n",
       "4   ExtraTreesRegressor  0.562159   0.640291  0.713069   0.06441   \n",
       "5   ExtraTreesRegressor  0.559267   0.639717  0.714048  0.065789   \n",
       "0   ExtraTreesRegressor  0.540789    0.63834  0.705965  0.063785   \n",
       "6   ExtraTreesRegressor  0.552307   0.636964   0.71336  0.069199   \n",
       "7   ExtraTreesRegressor  0.550408   0.635966   0.71026   0.06881   \n",
       "\n",
       "   model__max_depth model__n_estimators  \n",
       "19               16                 200  \n",
       "18               16                 150  \n",
       "20               16                 250  \n",
       "21               16                 300  \n",
       "17               16                 100  \n",
       "27               32                 200  \n",
       "35             None                 200  \n",
       "36             None                 250  \n",
       "28               32                 250  \n",
       "26               32                 150  \n",
       "34             None                 150  \n",
       "11                8                 200  \n",
       "29               32                 300  \n",
       "37             None                 300  \n",
       "22               16                 500  \n",
       "13                8                 300  \n",
       "10                8                 150  \n",
       "12                8                 250  \n",
       "9                 8                 100  \n",
       "30               32                 500  \n",
       "38             None                 500  \n",
       "16               16                  50  \n",
       "31               32                1000  \n",
       "39             None                1000  \n",
       "14                8                 500  \n",
       "23               16                1000  \n",
       "25               32                 100  \n",
       "33             None                 100  \n",
       "8                 8                  50  \n",
       "15                8                1000  \n",
       "24               32                  50  \n",
       "32             None                  50  \n",
       "1                 2                 100  \n",
       "3                 2                 200  \n",
       "2                 2                 150  \n",
       "4                 2                 250  \n",
       "5                 2                 300  \n",
       "0                 2                  50  \n",
       "6                 2                 500  \n",
       "7                 2                1000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After an extensive search where I spent time adjusting the values of our Hyperparameters we can clearly see that the  ExtraTreesRegroosr with a max_depth of 16 and an n_estimators of 200 is the most optimised.\n",
    "* To reitterate the goal was an r2 of 0.75.\n",
    "* with our tuned Hyperparameters:\n",
    "    * min r2 = 0.706932 \n",
    "    * max r2 = 0.84859\n",
    "    * mean r2 = 0.803771\n",
    "    * std r2 = 0.054214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ExtraTreesRegressor'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 16, 'model__n_estimators': 200}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;OrdinalCategoricalEncoder&#x27;,\n",
       "                 OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
       "                                variables=[&#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;,\n",
       "                                           &#x27;GarageFinish&#x27;, &#x27;KitchenQual&#x27;])),\n",
       "                (&#x27;NumericLogTransform&#x27;,\n",
       "                 LogTransformer(variables=[&#x27;1stFlrSF&#x27;, &#x27;GrLivArea&#x27;,\n",
       "                                           &#x27;LotArea&#x27;])),\n",
       "                (&#x27;NumericYeoJohnsonTransform&#x27;,\n",
       "                 YeoJohnsonTransformer(variables=[&#x27;BsmtUnfSF&#x27;])),\n",
       "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;cardinality&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor(random_state=0))),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestRegressor(max_depth=16, n_estimators=200,\n",
       "                                       random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;OrdinalCategoricalEncoder&#x27;,\n",
       "                 OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
       "                                variables=[&#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;,\n",
       "                                           &#x27;GarageFinish&#x27;, &#x27;KitchenQual&#x27;])),\n",
       "                (&#x27;NumericLogTransform&#x27;,\n",
       "                 LogTransformer(variables=[&#x27;1stFlrSF&#x27;, &#x27;GrLivArea&#x27;,\n",
       "                                           &#x27;LotArea&#x27;])),\n",
       "                (&#x27;NumericYeoJohnsonTransform&#x27;,\n",
       "                 YeoJohnsonTransformer(variables=[&#x27;BsmtUnfSF&#x27;])),\n",
       "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;cardinality&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor(random_state=0))),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestRegressor(max_depth=16, n_estimators=200,\n",
       "                                       random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
       "               variables=[&#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;GarageFinish&#x27;,\n",
       "                          &#x27;KitchenQual&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogTransformer</label><div class=\"sk-toggleable__content\"><pre>LogTransformer(variables=[&#x27;1stFlrSF&#x27;, &#x27;GrLivArea&#x27;, &#x27;LotArea&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">YeoJohnsonTransformer</label><div class=\"sk-toggleable__content\"><pre>YeoJohnsonTransformer(variables=[&#x27;BsmtUnfSF&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;cardinality&#x27;,\n",
       "                         threshold=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestRegressor(random_state=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=16, n_estimators=200, random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('OrdinalCategoricalEncoder',\n",
       "                 OrdinalEncoder(encoding_method='arbitrary',\n",
       "                                variables=['BsmtExposure', 'BsmtFinType1',\n",
       "                                           'GarageFinish', 'KitchenQual'])),\n",
       "                ('NumericLogTransform',\n",
       "                 LogTransformer(variables=['1stFlrSF', 'GrLivArea',\n",
       "                                           'LotArea'])),\n",
       "                ('NumericYeoJohnsonTransform',\n",
       "                 YeoJohnsonTransformer(variables=['BsmtUnfSF'])),\n",
       "                ('SmartCorrelatedSelection',\n",
       "                 SmartCorrelatedSelection(method='spearman',\n",
       "                                          selection_method='cardinality',\n",
       "                                          threshold=0.6)),\n",
       "                ('feat_scaling', StandardScaler()),\n",
       "                ('feat_selection',\n",
       "                 SelectFromModel(estimator=RandomForestRegressor(random_state=0))),\n",
       "                ('model',\n",
       "                 RandomForestRegressor(max_depth=16, n_estimators=200,\n",
       "                                       random_state=0))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* These are the 4 most important features in descending order. The model was trained on them: \n",
      "['1stFlrSF', 'GarageArea', 'GrLivArea', 'YearBuilt']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# after data cleaning and feat engine, the feature may space changes\n",
    "data_cleaning_feat_eng_steps = 4 # how many data cleaning and feature engineering does your pipeline have?\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "          'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "          'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "  .sort_values(by='Importance', ascending=False)\n",
    "  )\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{best_features}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What this plot shows us is that the 4 most important features needed to determine SalesPrice are as follows:\n",
    "    * GrLivArea\n",
    "    * YearBuilt\n",
    "    * GarageArea\n",
    "    * 1stFlrSf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline Performace on Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_performance(X_train, y_train, X_test, y_test,pipeline):\n",
    "\tprint(\"Model Evaluation \\n\")\n",
    "\tprint(\"* Train Set\")\n",
    "\tregression_evaluation(X_train,y_train,pipeline)\n",
    "\tprint(\"* Test Set\")\n",
    "\tregression_evaluation(X_test,y_test,pipeline)\n",
    "\n",
    "def regression_evaluation(X,y,pipeline):\n",
    "  prediction = pipeline.predict(X)\n",
    "  print('R2 Score:', r2_score(y, prediction).round(3))  \n",
    "  print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))  \n",
    "  print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))  \n",
    "  print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "  pred_train = pipeline.predict(X_train)\n",
    "  pred_test = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
    "  sns.scatterplot(x=y_train , y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "  sns.lineplot(x=y_train , y=y_train, color='red', ax=axes[0])\n",
    "  axes[0].set_xlabel(\"Actual\")\n",
    "  axes[0].set_ylabel(\"Predictions\")\n",
    "  axes[0].set_title(\"Train Set\")\n",
    "\n",
    "  sns.scatterplot(x=y_test , y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "  sns.lineplot(x=y_test , y=y_test, color='red', ax=axes[1])\n",
    "  axes[1].set_xlabel(\"Actual\")\n",
    "  axes[1].set_ylabel(\"Predictions\")\n",
    "  axes[1].set_title(\"Test Set\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push files to Repo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  # create here your folder\n",
    "  # os.makedirs(name='')\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
