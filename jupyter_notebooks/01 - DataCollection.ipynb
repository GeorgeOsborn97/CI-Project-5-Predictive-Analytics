{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook objectives\n",
    "\n",
    "* Fetch data from Kaggle and save it as raw data.\n",
    "* Inspect the data and save it under outputs/datasets/collection\n",
    "* Push the files to Github"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "* Kaggle JSON file - the authentication token.\n",
    "* Download the appropriate data set from Kaggle, specified in the Code Institute Lessons "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Comments\n",
    "\n",
    "* This Notebook follows the structure set out during the two Code Instutute Walkthrough Projects that relate to Predictive Analytics and is based on the Template provided in the Assessment Handbook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working Directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to make the parent of the current directory the new current directory\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect The Data from Kaggle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. first we must install the Kaggle package in order to fetch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install kaggle==1.5.12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. With the kaggle package installed we must then import our specific Kaggle authentification token, which is stored in a Kaggle.json file.\n",
    "    * In order to access one of these tokens you must create an acount with Kaggle, from there you may download a personal token that will give you access to Kaggles Datasets.\n",
    "    * Once you have downloaded this token drag and drop the kaggle.json file into the root directory.\n",
    "    * Now we can set the Kaggle enviroment variable so the token can be recognised by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. After setting our environment we can finally access our required dataset from kaggle and place it into a folder within our directory, in order to do so we run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPath = \"codeinstitute/housing-prices-data\"\n",
    "DestinationFolder = \"inputs/datasets/raw\"\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The dataset is downloaded as a .zip, therefore we must unzip the file in order to view and use our data, do so by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
    "    && rm {DestinationFolder}/*.zip \\\n",
    "    && rm kaggle.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our required dataset is now accessable and ready to be inspected.\n",
    "    * As a note is important to see we have downloaded 2 datasets in 2 .csv files. The first is our house_price_records dataset, this will be used to train and test the model. The other is the inherited_houses dataset, the data here is the subject of our business case. As stated in the Readme our aim is to accuratly predict the sales price of the houses in this dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect our newly downloaded datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first thing we will do is install Pandas in order to place our first dataset (house_price_records.csv) into a dataframe, we do this so we can easily view and inspect our data.\n",
    "    * we can then visualise the top 5 rows of our dataset using .head() on our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To then see a summary of our data, we can use .info() on our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see here that our data contains 24 columns ranging from 1stFlrSF to SalePrice, we have 7 coloumns that are float64, 13 columns that are int64, and 4 columns that are objects.\n",
    "* We can also see in this summary the non-null count for each column. \n",
    "* In the DataAnalysis Notebook we will dive deeper into our data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We will now repeat the above steps for our inherited_houses data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inherited = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\")\n",
    "print(df_inherited.shape)\n",
    "df_inherited.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inherited.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking quickly over this data we can see we have 4 rows, showing our 4 inherited houses and 23 columns. The obvious difference here to the previous dataset is that SalesPrice is not present. This is because the SalesPrice is unknown and shall be the target of the model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With our data loaded and inspected there a couple of aspects to note.\n",
    "    1. Salesprice is not present in the inherited_houses dataset. This however is expected as the prediction of the SalesPrice of these houses is the problem defined in our business case.\n",
    "    2. There are diffrences in the data types in matching columns between datasets. For example 2ndFlrSF in house_price_records is type float64, where as it is type int64 in the inherited_houses dataset. This will be resolved in the DataCleaning Notebook.\n",
    "* From this point we have our data loaded and can move on to Data Analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
