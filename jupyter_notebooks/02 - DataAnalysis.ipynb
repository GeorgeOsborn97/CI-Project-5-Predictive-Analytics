{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "### An exploratory data analysis of our collected data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "1. Answer our first Business requirement. \n",
    "    * Perform a correlation and/or PPS study to investigate the most relevant variables correlated to the sale price.\n",
    "    * Visualize these variables against the sale price, in order to summarize the insights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "1. Our house_price_records data that we collected in our DataCollection Notebook, found at inputs/datasets/raw/house-price-20211124T154130z/house-price/house_price_records.csv "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "\n",
    "1. Code that succesfully generates the answers to our first business requirement.\n",
    "2. Plotted graphs that visualise the results found during correlation testing.\n",
    "3. Useful and insightful analysis of the found results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook was designed and follows the principles set out by Code Institute in the Predictive Analytics lessons and Walkthrough projects. The code written in this work book has taken influence from these lessons and projects but has been modiefied, in some cases such as the graphical design, heavily modified by myself in order to suit the needs for this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working Directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to make the parent of the current directory the new current directory\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is simply to load in our raw data that we collected in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = (pd.read_csv(\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With our data loaded we can begin to analyse it. \n",
    "    * To begin with I have generated a panadas profile report, this is a an automated dashboard used for quick EDA (Exploratory Data Analysis), simply run the code below to genorate the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=df, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas report we have generated provides a lot of very useful insights, we can see straight away a summary of each variable in our data. This summary details information such as the mean, min and max values, the number of missing values if any, and a graph showing the distribution of values.\n",
    "\n",
    "* An instant take away from this report is the amount of missing values, if we have a look at the alerts tab we can see that 8 columns contain missing values. Missing values appear in both numerical and categorical variables, there are various different avenues we can take to deal with missing values. These will be reviewed in Data Cleaning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Study"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Firstly in order to assess the correlation between Sales price and any numerical variables in our dataset I will use Spearman and Pearson correlation tests on our raw data.\n",
    "    * Pearson correlation assess the linear relationship between two variables and produces a value between -1 and +1, donating a negative or positive correlation respectivly. a value of 0 indictaes no corraelation between the variables.\n",
    "    * Spearman correlation assess the monotonic relation between vairables. Again it provides a value between -1 and +1.\n",
    "\n",
    "2. These two tests only evaluate the correlation of numerical values. Therefore we are not getting any correlation information regarding our categorical variables such as Kitchen Quality. \n",
    "    * In order to evaluate these variables in conjucture with the rest I will perform some simple data cleaning and feature engineering.\n",
    "    * The data will have the null values amended, categorical variables will have 'missing' in place of null values, and the mean will be added in place of any null values in the numerical data.\n",
    "    * One hot encoder will then be used to convert the categorical variables to a binary classification allowing us to evaluate them using spearman and pearson correlation tests.\n",
    "3. The results of these 4 tests will then be evaluated and the leading variables that show the greatest correlation will be plotted.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spearman = df.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
    "corr_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson = df.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
    "corr_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from feature_engine.imputation import DropMissingData, MeanMedianImputer, CategoricalImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('mmi', MeanMedianImputer(imputation_method='mean', variables=['2ndFlrSF','EnclosedPorch','GarageYrBlt','LotFrontage','WoodDeckSF'])),\n",
    "    ('ci', CategoricalImputer(imputation_method='missing', variables=['BsmtExposure','BsmtFinType1','GarageFinish','KitchenQual'])),\n",
    "    ('ohe', OneHotEncoder(variables=['BsmtExposure','BsmtFinType1','GarageFinish','KitchenQual'], drop_last=False))\n",
    "])\n",
    "df_ohe = pipeline.fit_transform(df)\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spearman_ohe = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
    "corr_spearman_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson_ohe = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
    "corr_pearson_ohe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completion of our correlation tests, we can take the top 6 correlation levels for both sets of tests to review if any differences have arised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set(corr_pearson_ohe[:top_n].index.to_list() + corr_spearman_ohe[:top_n].index.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that both sets of tests have produced the same top 6 most correlated variables. The findings are as follows:\n",
    "    1. A house with a high sales price typically has a large 1st floor square footage.\n",
    "    2. A house with a high sales price typically has a large garage square footage.\n",
    "    3. A house with a high sales price typically has a large above grade (ground) living area square footage.\n",
    "    4. A house with a high sales price typically has a high overall quality.\n",
    "    5. A house with a high sales price typically has a large basement square footage.\n",
    "    6. A house with a high sales price typically was built more recently."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the raw data (df) to plot graphs of the target variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variables = ['1stFlrSF', 'GarageArea', 'GrLivArea', 'OverallQual', 'TotalBsmtSF', 'YearBuilt']\n",
    "target_variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on target_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df.filter(target_variables + ['SalePrice'])\n",
    "df_eda.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def plot_numerical(df, col, target_var):\n",
    "    fig = px.scatter(data_frame=df_eda, x=col, y=target_var, marginal_x='box', trendline='ols', trendline_color_override='red' ,title=f'{col} against {target_var}',width=1400, height=800)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "target_var = 'SalePrice'\n",
    "for col in target_variables:\n",
    "    plot_numerical(df_eda, col, target_var)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To review, the 6 variables that were highligthed and our assumptions made on them are as follows:\n",
    "    1. A house with a high sales price typically has a large 1st floor square footage.\n",
    "    2. A house with a high sales price typically has a large garage square footage.\n",
    "    3. A house with a high sales price typically has a large above grade (ground) living area square footage.\n",
    "    4. A house with a high sales price typically has a high overall quality.\n",
    "    5. A house with a high sales price typically has a large basement square footage.\n",
    "    6. A house with a high sales price typically was built more recently.\n",
    "\n",
    "\n",
    "* Upon further analysis of these variables through plotting we can confirm that each variable does indeed have a strong postive correlation to the sales price as indicated by our postive trendlines. Therefore we can assume they may, be well suited for predicting the future sales price of an unseen house.\n",
    "    * It is clear through our analysis that some of our identified varibales look to have a greater impact then others, for example the GrLivArea and TotalBsmtSF look to have a greater influence over sales price then the year built. However all variables look to have an impact so all will be considered during our modelling.\n",
    "\n",
    "* The next step is to clean the data prior to feature engineering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
