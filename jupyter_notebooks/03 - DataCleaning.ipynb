{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "1. Load in the raw dataset for further analysis and preporation for data cleaning.\n",
    "2. Revisit correlation and perform a PPS (Predictive Power Score) Study.\n",
    "3. Inspect the data set for missing values, with a focus on the features highlighted in the DataAnalysis Notebook.\n",
    "4. Having dealt with any missing values split the now clean data set into Train and Test sets.\n",
    "5. Push these new data sets to the repo ready for feature engineering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "1. Our house_price_records data that we collected in our DataCollection Notebook, found at inputs/datasets/raw/house-price-20211124T154130z/house-price/house_price_records.csv "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook was designed and follows the principles set out by Code Institute in the Predictive Analytics lessons and Walkthrough projects. The code written in this work book has taken influence from these lessons and projects but has been modiefied, in some cases such as the graphical design, heavily modified by myself in order to suit the needs for this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working Directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to make the parent of the current directory the new current directory\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Collected Data and Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "from feature_engine.imputation import ArbitraryNumberImputer, CategoricalImputer, MeanMedianImputer, DropMissingData\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Firstly load both datasets ready for data evalustaion and cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inherited = (pd.read_csv(\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\"))\n",
    "df_inherited.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having loaded our data we want to assess the distribution of the variables that contain missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the Pandas Profile Report again, however this time we have singled out the columns that contain missing features in order to get a better understanding of their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vars_with_missing_data:\n",
    "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "    profile.to_notebook_iframe()\n",
    "else:\n",
    "    print(\"There are no variables with missing data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPS Analysis and Revisit of Correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Code utilised here was taken from the Code Isntitute lessons focused around PPS (Predictive Power score).\n",
    "* We are utilising heatmaps here to review the PPS and correlation between our target Sales Price and other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\")\n",
    "    df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "    print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate the PPS (Predictive Power Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below is the calling of our above function, we have set the PPS_threshhold at 0.2 in order to get a visualisation of features that have a relativly weak to strong predictive power. A score of less then 0.2 would mean a very weak predictive power and would arguably not be worth our time investigating.\n",
    "* As seen in the previous notebook the features we highlighted as potentail features of importance showed a strong corralation, as such the correlation threshhold has been set to 0.5 and we would hope to see all 6 of these features present in the heat maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.5, PPS_Threshold =0.2,\n",
    "                  figsize=(12,10), font_annot=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Data Analysis\n",
    "### Missing data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateMissingData(df):\n",
    "    missing_data_absolute = df.isnull().sum()\n",
    "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
    "    df_missing_data = (pd.DataFrame(\n",
    "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
    "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
    "                                   \"DataType\": df.dtypes}\n",
    "                                    )\n",
    "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
    "                          .query(\"PercentageOfDataset > 0\")\n",
    "                          )\n",
    "\n",
    "    return df_missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df_inherited)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results of missing data evaluation\n",
    "\n",
    "* As we can see we have 9 columns that contain missing data, with both EnclosedPorch and WoodDeckSF having a hugely significant portion of their data missing.\n",
    "* The other columns do not have nearly as much missing data as the previously mentioned two, however the amount if missing data is still an issue.\n",
    "* The brightside here is that none of the features that were intially flagged as potentially important in the previous notebook appear in this list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effects of data cleaning methods\n",
    "\n",
    "* In the previous notebook we completed some very simple data cleaning just to get a rough look at what effect it would have on the features that we identefied as potentally important. We wanted to see there that if after some simple cleaning and engineering whether those features remained the most important.\n",
    "* The above PPS and correlation tests have then reinforced that based on the raw data we collected the top features that look to be able to predict SalePrice are:\n",
    "    1. A large 1st floor square footage. (1stFlrSF)\n",
    "    2. A large garage square footage. (GarageArea)\n",
    "    3. A large above grade (ground) living area square footage. (GrLivArea)\n",
    "    4. A high overall quality. (OverallQual)\n",
    "    5. A large basement square footage. (TotalBsmtSF)\n",
    "    6. A house built more recently. (YearBuilt)\n",
    "\n",
    "\n",
    "* What we shall now look at is a more in-depth look into the effects of different data cleaning methods, The code below has been taken from the Code Institute Lessons relating to Predictive Analytics.\n",
    "    * The below function assess the effect of different data cleaning methods such replacing missing numerical values with the Mean or the Median, and replacing Categorical values with 'Missing' or the most frequently seen value. \n",
    "    * Once we have gone through and cleaned our data producing a new cleaned dataframe we shall use this function to evaluate any significant changes to the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
    "\n",
    "  flag_count=1 # Indicate the plot number\n",
    "  \n",
    "  # Distinguish between numerical and categorical variables\n",
    "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
    "\n",
    "  # scan over the variables, \n",
    "    # first on variables that you applied to the method\n",
    "    # if the variable is numerical plot a histogram, if categorical plot a barplot\n",
    "  for set_of_variables in [variables_applied_with_method]:\n",
    "    print(\"\\n=====================================================================================\")\n",
    "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
    "    print(f\"{set_of_variables} \\n\\n\")\n",
    "  \n",
    "\n",
    "    for var in set_of_variables:\n",
    "      if var in categorical_variables:  # it is categorical variable: barplot\n",
    "        \n",
    "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
    "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
    "        dfAux = pd.concat([df1, df2], axis=0)\n",
    "        fig , axes = plt.subplots(figsize=(15, 5))\n",
    "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend() \n",
    "\n",
    "      else: # it is numerical variable: histogram\n",
    "\n",
    "        fig , axes = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
    "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.legend() \n",
    "\n",
    "      plt.show()\n",
    "      flag_count+= 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can start the cleaning process by returning to an earlier function and pulling our columns that contain missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As previously stated both EnclosedPorch and WoodDeckSF have an extreamly high percentage of null values. It is therefore not viable to attempt to impute any values in place of these, for this reason we shall be dropping these columns entirely from our dataset.\n",
    "* LotFrontage and GarageFinish also have a high percentage of null values. Both above 10%. They shall not be immediatly dropped without evaluation however as they may still provide insights after data cleaning.\n",
    "* The remaining 5 variables will all be cleaned and evaluated using the function defined above.\n",
    "\n",
    "* It is my assumption that due to the fact none of these variables have been flagged in any data analysis as potentially useful for predicting SalesPrice that after data cleaning they will still prove to be unimportant, however we can not confirm this assumption without performing the relevent data cleaning and subsequent evaluation. The only 2 exceptoions to this are EnclosedPorch and WoodDeckSF. Both of which are float64 variables with 90% null values meaning any mean, median or arbitary number imputation would not be close to a relistic representation of the data and will not aid in our predictions and could even have a negative impact if any."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning we will try initially\n",
    "1. Drop - ['EnclosedPorch', 'WoodDeckSF' ]\n",
    "2. Arbitary Number Imputer - ['2ndFlrSF', 'BedroomAbvGr', 'MasVnrArea'] \n",
    "3. Impute the Mean - ['LotFrontage', 'GarageYrBlt' ]\n",
    "4. Impute 'Missing' - ['GarageFinish', 'BsmtFinType1' ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splt the cleaned data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step when cleaning is to create a copy of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split our original dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TrainSet, TestSet, _, __ = train_test_split(\n",
    "                                        df,\n",
    "                                        df['SalePrice'],\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0)\n",
    "\n",
    "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the spread of missing values with in the test set that we have just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_data = EvaluateMissingData(TrainSet)\n",
    "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
    "df_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Upon reviweing the test set we can see the split is extrealy similar to the split of the raw data. As expected the same 9 variables have been flagged with a slight decrease in the the percantage of missing data, however we still see theat EnclosedPorch and WoodDeckSF have 90.41% and 88.53% missing data respectivly so we shall continue to work on the assumption that they will be of no help in answering the business requiremets and will be dropped due to this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 of data cleaning\n",
    "\n",
    "* As stated above we want to drop EnclosedPorch and WoodDeckSF as they have a large majority of null values and will likely not effect our predictions in any meaningful way.\n",
    "* In order to achieve this we will run the following code, utilising the DropFeatures meathod from feature_engine and will apply this change to both the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropFeatures\n",
    "variables = ['EnclosedPorch', 'WoodDeckSF']\n",
    "imputer = DropFeatures(features_to_drop=variables)\n",
    "imputer.fit(TrainSet)\n",
    "TrainSet, TestSet = imputer.transform(TrainSet), imputer.transform(TestSet)\n",
    "TestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = imputer.transform(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check again that our code worked by placing all columns with null values into a list, as we can see EnclosedPorch and WoodDeckSF are no longer present as they have been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "null_variables = TrainSet.columns[TrainSet.isnull().any()].tolist()\n",
    "print(null_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 of Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above we have a large list of columns all of which were float64 variables, that we, as a base defined imputing the mean as a potential solution. However upon inspection of the data, we can deduce that imputing the mean my not be the most optimum solution.\n",
    "The float64 variables are: ['2ndFlrSF', 'BedroomAbvGr', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking closly at the raw data set we can make some assumptions about the missing data which will help in our data cleaning.\n",
    "* The first thing I noticed when looking more deeply into our data is that 2ndFlrSF has a very large amount of 0 values (626 rows). We can assume this is due to the propertty being a bungalow and therefore having no second floor area. Further more the null value count is relativy low (60 rows), for this reason we can safely assume that if we convert our null values to 0 values we will not negatively impact our data.\n",
    "* Secondly BedroomAbvGr is a grading system of bedrooms from 0-8. On first impressions it looks like there is no accurate way to remove the null values, our heat map shows that there are no other variables with the ability to predict BedroomAbvGr and imputing the mean or median would be inaccurate and could negatively effect our predictions. However when we look at our Inherited_df (the data we want to predict). We can see that all the houses have an BedroomAbvGr > 0. Due to this we can set all our null values to 0 using ArbitaryNumberImputer just like 2nfFlrSF.\n",
    "* Thirdly MasVnrArea follows a very similar trend to 2ndFlrSF. It has a very high count of 0 values. Which to me indicates that these houses have no Masonry Veneer. Furthermore in terms of the null value count there are only 8 rows with null values. Due to these reasons and the fact that the heat map showed no predictive power for MasVnrArea I am confident we may also impute 0 for null values in this field without negatively impacting our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['2ndFlrSF'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['BedroomAbvGr'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['MasVnrArea'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('2ndFlrSF_BedrromAbvGr_MasVnrArea', ArbitraryNumberImputer(arbitrary_number=0, variables=['2ndFlrSF', 'BedroomAbvGr', 'MasVnrArea']))\n",
    "])\n",
    "pipeline.fit(TrainSet)\n",
    "TrainSet, TestSet = pipeline.transform(TrainSet), pipeline.transform(TestSet)\n",
    "df_clean = pipeline.transform(df_clean)\n",
    "EvaluateMissingData(TrainSet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see when we evaluate missing data in our train set 2ndFlrSF, BedroomAbvGr and MasVnrArea are no longer present. To double check our pipeline worked we will also check the missing values in our clean dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 of Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have 4 columns left that contain null values and require cleaning. The next one that I believe will be easily sorted is LotFrontage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['LotFrontage'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the LotFrontage data we can see it contains 212 rows of missing data. (Just under 18%)\n",
    "The values range from 21.0 to 313.0. If we go back and look at the Pandas Profiling report we can see that the mean is 70.05 if we round to 2 decimal places and it has no 0 values. My first impression is to use to Impute the mean using MeanMedainImputer to all null values. Again we can see from the heat map LotFrontage holds no predictive power so we shouldn't have to worry about negative impacts to our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer = MeanMedianImputer(imputation_method='mean', variables=['LotFrontage'])\n",
    "mean_imputer.fit(TrainSet)\n",
    "TrainSet, TestSet = mean_imputer.transform(TrainSet), mean_imputer.transform(TestSet)\n",
    "df_clean = mean_imputer.transform(df_clean)\n",
    "EvaluateMissingData(TrainSet)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again upon inspection we can see our last 3 variables that contain null values, indicting our code worked on LotFrontage. We will test again though on the clean dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 of Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next variable to look at is BsmtFinType1 which is an object variable refering to the state of the basement that is finished. The first thing to do is inspect the varible itself. We already know that within our test set there are 89 rows containing missing data. We also know that from reviewing the heatmap that BsmtFinSF1 could be used to predict BsmtFinType1. We also have a lot of other variables that refer to the basement. For example TotalBsmtSF, it stands to reason that any house with a TotalBsmtSF that equals 0 does not have a basement. Therefore The BsmtFinType1 should equal 'None', we can query this and make sure this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TrainSet['BsmtFinType1'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet['BsmtFinType1'].isna()].query('TotalBsmtSF==0').sort_values(by=['TotalBsmtSF'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see 3 properties have 0 TotalBsmtSF and missing data, we can impute 'None' for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_condition = (TrainSet.TotalBsmtSF == 0) & (TrainSet['BsmtFinType1'].isnull())\n",
    "TrainSet['BsmtFinType1'] = np.where(train_query_condition, 'None', TrainSet['BsmtFinType1'])\n",
    "\n",
    "test_query_condition = (TestSet.TotalBsmtSF == 0) & (TestSet['BsmtFinType1'].isnull())\n",
    "TestSet['BsmtFinType1'] = np.where(test_query_condition, 'None', TestSet['BsmtFinType1'])\n",
    "\n",
    "df_clean_query_condition = (df_clean.TotalBsmtSF == 0) & (df_clean['BsmtFinType1'].isnull())\n",
    "df_clean['BsmtFinType1'] = np.where(df_clean_query_condition, 'None', df_clean['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet['BsmtFinType1'].isna()].query('TotalBsmtSF==0').sort_values(by=['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['BsmtFinType1'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our two tests, we have imputed None into our 3 rows and they no longer appear when we query TotalBsmtSF = 0 and null values. we can also see our total rows with null values has decreased by 3 to a total of 86."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar method to our previous 3 rows, we shall query the null values of BsmtFinType1 against BsmtFinSF1. The aformentioned variable describes the surface area of the basement that is finished. if the value of this is 0 then we can conclude that the basment is unfinished and therefore we can impute 'Unf' into our null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['BsmtFinSF1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unf_df = TrainSet[TrainSet['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['BsmtFinSF1'])\n",
    "print(unf_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have 27 rows where we can conclude that the Basment is unfinished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_condition = (TrainSet.BsmtFinSF1 == 0) & (TrainSet['BsmtFinType1'].isnull())\n",
    "TrainSet['BsmtFinType1'] = np.where(train_query_condition, 'Unf', TrainSet['BsmtFinType1'])\n",
    "\n",
    "test_query_condition = (TestSet.BsmtFinSF1 == 0) & (TestSet['BsmtFinType1'].isnull())\n",
    "TestSet['BsmtFinType1'] = np.where(test_query_condition, 'Unf', TestSet['BsmtFinType1'])\n",
    "\n",
    "df_clean_query_condition = (df_clean.BsmtFinSF1 == 0) & (df_clean['BsmtFinType1'].isnull())\n",
    "df_clean['BsmtFinType1'] = np.where(df_clean_query_condition, 'Unf', df_clean['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['BsmtFinType1'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can see that our null values are dropping as we are imputing values. and we are left with 59 rows with null values.\n",
    "* The question is now how do we define these null values. As stated earlier there are other factors that can be used to predict BsmtFinType1. However the work needed to produce a model that could accurately predict BsmtFinType1 would be great and would it add value to our business requirements? Looking at the heatmap and correlation we can see that BsmtFinType1 has no correlation to SalesPrice and does not hold any predictive power towards it. Therefore I assume that there is no real need to get a accurate value for these remaining rows. For this reason we will simply use the CatergoricalImputer to place 'Unknown' in place of these values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_imputer = CategoricalImputer(\n",
    "    imputation_method='missing', fill_value='Unknown', variables='BsmtFinType1'\n",
    "    )\n",
    "unknown_imputer.fit(TrainSet)\n",
    "TrainSet, TestSet, df_clean = unknown_imputer.transform(TrainSet), unknown_imputer.transform(TestSet), unknown_imputer.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(TrainSet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have our final 2 variables left to clean. These have been left till last as they both refer to the garage and like with the BsmtFinType1 we may see links that help us impute accurate data for the null values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 of Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first variable out of the final two we shall look at is GarageFinish, which is an object variable that refers to the state of the garage. First we shall inspect the data. We already know from above that there are 131 rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['GarageFinish'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the method used when cleaning BsmtfinType1, we shall use another variable to infer information about the GarageFinish. If we look at GarageArea, we can assume that if GarageArea equals 0 then GarageFinish should equal 'None'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet['GarageFinish'].isna()].query('GarageArea==0').sort_values(by=['GarageArea'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have 5 rows where GarageFinish is null and GarageArea equals 0. Like before we shall impute 'None' into these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_condition = (TrainSet.GarageArea == 0) & (TrainSet['GarageFinish'].isnull())\n",
    "TrainSet['GarageFinish'] = np.where(train_query_condition, 'None', TrainSet['GarageFinish'])\n",
    "\n",
    "test_query_condition = (TestSet.GarageArea == 0) & (TestSet['GarageFinish'].isnull())\n",
    "TestSet['GarageFinish'] = np.where(test_query_condition, 'None', TestSet['GarageFinish'])\n",
    "\n",
    "df_clean_query_condition = (df_clean.GarageArea == 0) & (df_clean['GarageFinish'].isnull())\n",
    "df_clean['GarageFinish'] = np.where(df_clean_query_condition, 'None', df_clean['GarageFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet['GarageFinish'].isna()].query('GarageArea==0').sort_values(by=['GarageArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['GarageFinish'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our count of null values has reduced by 5 indicating our code has worked. We can double check that 'None' has increased by 5 by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['GarageFinish'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortuantly there are no other variables that we can use that will give insight into the GarageFinish. And after a review of the PPS heatmap we can see that GarageFinihs holds no predictive power on the business requirement (SalesPrice). For this reason we shall again impute 'Unknown' to the rest of the null values for GarageFinish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_imputer = CategoricalImputer(\n",
    "    imputation_method='missing', fill_value='Unknown', variables='GarageFinish'\n",
    "    )\n",
    "unknown_imputer.fit(TrainSet)\n",
    "TrainSet, TestSet, df_clean = unknown_imputer.transform(TrainSet), unknown_imputer.transform(TestSet), unknown_imputer.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['GarageFinish'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(TrainSet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we now have our 'Unknown' values in GarageFinish, and upon evaluating the missing data the only variable left is GarageYrBlt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 of Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final Variable to be cleaned is GarageYrBlt, which refers to the year in which the garage is built, it is a float64 variable with 58 null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet['GarageYrBlt'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the assumption that a null value is GarageyrBlt indicates that there is no garage. If that is the case then GarageFinish should equal None at the same instance that we have our null values. We can test this by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = TrainSet[TrainSet['GarageYrBlt'].isna()].query('GarageFinish==\"None\"').sort_values(by=['GarageFinish'])\n",
    "print(query_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the code has returned the shape of the dataframe produced by our query. The shape shows that there are 58 rows where GarageFinish is 'None' and GarageYrBlt is null proving our assumption.\n",
    "We shall use Arbitary Number Imputer to place 0 into the null values reflecting the fact that no garage has been built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "      ( 'GarageYrBlt',  ArbitraryNumberImputer(\n",
    "        arbitrary_number=0, variables='GarageYrBlt'\n",
    "        ) \n",
    "      )\n",
    "])\n",
    "pipeline\n",
    "\n",
    "pipeline.fit(TrainSet)\n",
    "TrainSet, TestSet, df_clean = pipeline.transform(TrainSet), pipeline.transform(TestSet),pipeline.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(TrainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see after our previous two cells we have cleaned all the data and have no null values left in our data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed all null values in our cleaned dataframe, train and test sets. we can utilise the DataCleaningEffect function that we defined earlier on in this notebook.\n",
    "* This function plots our original dataframe against our clean dataframe so we can see the effect of our data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCleaningEffect(df_original=df,\n",
    "                   df_cleaned=df_clean,\n",
    "                   variables_applied_with_method=null_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking at the effect on the distribution of these variables we can see a bit more of a peak at LotFrontage where we imputed the mean.\n",
    "* The GarageYrBlt is skewed heavily due to the addition of 0 values.\n",
    "* Everything else has remained very similar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Datatypes across df_clean and df_inherited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inherited.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.select_dtypes('object').info())\n",
    "print(df_clean.select_dtypes('float').info())\n",
    "print(df_clean.select_dtypes('int').info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_inherited.select_dtypes('object').info())\n",
    "print(df_inherited.select_dtypes('float').info())\n",
    "print(df_inherited.select_dtypes('int').info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the above code we can see there are some discrepencies in the data types between the cleaned dataframe and inherited dataframe. We want to rectify this that the data types are like for like across dataframes.\n",
    "* All the object type variables are the same so require no change.\n",
    "* There are 5 float64 variables in df_clean and 7 in df_inherited.\n",
    "* There there are 13 int64 variables in df_clean and 12 in df_inherited.\n",
    "* For ease we will change all floats to ints. This will then be repeated in the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_clean.select_dtypes('float').columns:\n",
    "    df_clean[col] = df_clean[col].astype('int64')\n",
    "\n",
    "for col in df_inherited.select_dtypes('float').columns:\n",
    "    df_inherited[col] = df_inherited[col].astype('int64')\n",
    "\n",
    "print(df_clean.select_dtypes('float').info())\n",
    "print(df_inherited.select_dtypes('float').info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are now no more float variables, we can check our dataframes as a whole to make sure everthing worked as expected and the floats have become int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.info())\n",
    "print(df_inherited.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything working as expected we will now apply the same changes to the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in TrainSet.select_dtypes('float').columns:\n",
    "    TrainSet[col] = TrainSet[col].astype('int64')\n",
    "\n",
    "for col in TestSet.select_dtypes('float').columns:\n",
    "    TestSet[col] = TestSet[col].astype('int64')\n",
    "\n",
    "print(TrainSet.info())\n",
    "print(TestSet.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we can save our clean dataframe and our train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet.to_csv(\"outputs/datasets/cleaned/TestSet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"outputs/datasets/cleaned/clean_house_price_records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inherited.to_csv(\"outputs/datasets/cleaned/clean_inherited_houses.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion as we have worked through this workbook we have:\n",
    "* Further analysed our data to identify variables that required cleaning and gave thought to what would be the optimum method to do so.\n",
    "* we split our data into a train and test set.\n",
    "* We dropped varibales that we deemed unimportant to our business goal.\n",
    "* We stepped through each of our variables containing null values and cleaned them, replacing null values with values that best suited the data.\n",
    "* We then evaluated our data cleaning against the original data.\n",
    "* Finally we ensured that the clean data frame, test and train set and the inherited dataframe all had the same data types across all variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
